# Checkpoint 01 - Data Science e Machine Learning

## üìã Sobre o Projeto

Este projeto √© um checkpoint acad√™mico que demonstra t√©cnicas de Data Science e Machine Learning aplicadas a dados de consumo de energia el√©trica. O trabalho utiliza Python e Orange Data Mining para an√°lise explorat√≥ria, modelagem preditiva e visualiza√ß√£o de dados.

**Total de exerc√≠cios:** 40 (20 disponibilizados em 20/08 + 20 disponibilizados em 27/08)

**Estrutura da atividade:**
- **Parte 1:** Exerc√≠cios iniciais com Individual Household Electric Power Consumption (20 quest√µes)
- **Parte 2:** Exerc√≠cios adicionais no dataset inicial (5 quest√µes)  
- **Parte 3:** Novo dataset Appliances Energy Prediction (10 quest√µes)
- **Parte 4:** Exerc√≠cios no Orange Data Mining (5 quest√µes)

## üë• Equipe

- **Gustavo Bispo** - R558515
- **Gustavo Mon√ß√£o** - 557515  
- **Lucas Barreto** - 557107
- **Vinicius Murtinho** - 551151

## üìä Datasets Utilizados

### 1. Individual Household Electric Power Consumption
- **Arquivo**: `household_power_consumption.txt`
- **Fonte**: [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/235/individual+household+electric+power+consumption)
- **Per√≠odo**: Dezembro 2006 - Novembro 2010
- **Frequ√™ncia**: Medi√ß√µes a cada minuto
- **Tamanho**: ~2M registros, 9 vari√°veis
- **Vari√°veis principais**:
  - `Global_active_power`: Consumo ativo global (kW)
  - `Global_reactive_power`: Consumo reativo global (kW) 
  - `Voltage`: Tens√£o (V)
  - `Global_intensity`: Intensidade global (A)
  - `Sub_metering_1/2/3`: Submedi√ß√µes espec√≠ficas (kWh)

### 2. Appliances Energy Prediction
- **Arquivo**: `energydata_complete.csv`
- **Fonte**: [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/374/appliances+energy+prediction)
- **Per√≠odo**: Janeiro 2016 - Maio 2016
- **Frequ√™ncia**: Medi√ß√µes a cada 10 minutos
- **Tamanho**: ~19K registros, 28 vari√°veis
- **Vari√°veis principais**:
  - `Appliances`: Consumo de eletrodom√©sticos (Wh)
  - `T1-T9`: Temperaturas em diferentes ambientes
  - `RH_1-RH_9`: Umidade relativa em diferentes ambientes
  - `T_out`: Temperatura externa
  - `RH_out`: Umidade externa

## üõ†Ô∏è Tecnologias e Bibliotecas

### Python
- **NumPy** - Computa√ß√£o num√©rica
- **Pandas** - Manipula√ß√£o de dados
- **Matplotlib** - Visualiza√ß√£o
- **Scikit-learn** - Machine Learning
- **Statsmodels** - An√°lise de s√©ries temporais (opcional)

### Orange Data Mining
- Interface visual para an√°lise de dados
- Ferramentas de clustering e visualiza√ß√£o

## üìÅ Estrutura do Projeto

```
checkpoint_ds_ml.py              # Script principal com todas as an√°lises (40 exerc√≠cios)
household_power_consumption.txt  # Dataset de consumo dom√©stico (UCI)
energydata_complete.csv         # Dataset de eletrodom√©sticos (UCI)
README.md                       # Documenta√ß√£o do projeto
```

### Arquivos de Dados
- **household_power_consumption.txt**: Baixar de [UCI Repository](https://archive.ics.uci.edu/dataset/235/individual+household+electric+power+consumption)
- **energydata_complete.csv**: Baixar de [UCI Repository](https://archive.ics.uci.edu/dataset/374/appliances+energy+prediction)

## üöÄ Como Executar

### Pr√©-requisitos

#### Python
```bash
pip install numpy pandas matplotlib scikit-learn
pip install statsmodels  # Opcional para decomposi√ß√£o de s√©ries temporais
```

#### Orange Data Mining
- Baixar e instalar Orange Data Mining: https://orangedatamining.com/download/
- Vers√£o recomendada: 3.34+ (compat√≠vel com Python 3.8+)

### Execu√ß√£o

#### Python
```bash
python checkpoint_ds_ml.py
```

#### Orange Data Mining
1. Abrir Orange Data Mining
2. Usar os widgets conforme instru√ß√µes das quest√µes 36-40
3. Workflow sugerido: CSV File Import ‚Üí Data Table ‚Üí Sample Data ‚Üí Distribution/Scatter Plot ‚Üí k-Means

## üì± Google Colab - Execu√ß√£o Individual

### Prepara√ß√£o no Colab
```python
# 1. Instalar depend√™ncias
!pip install numpy pandas matplotlib scikit-learn statsmodels

# 2. Fazer upload dos datasets
from google.colab import files
uploaded = files.upload()

# 3. Definir constantes
POWER_PATH = "household_power_consumption.txt"
APPLIANCES_PATH = "energydata_complete.csv"
RANDOM_STATE = 42

# 4. Importar bibliotecas
import warnings
warnings.filterwarnings("ignore")
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.metrics import mean_squared_error, confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split

try:
    from statsmodels.tsa.seasonal import seasonal_decompose
    HAS_STATSmodels = True
except Exception:
    HAS_STATSmodels = False
    print("Aviso: statsmodels n√£o encontrado. A decomposi√ß√£o de s√©rie temporal (Q19) ser√° pulada.")
```

### Fun√ß√µes Auxiliares para Colab
```python
def parse_power_dataset(path):
    '''Carrega o dataset 'Individual Household Electric Power Consumption' do UCI.'''
    df = pd.read_csv(path, sep=';', na_values='?', low_memory=False)
    numeric_cols = ['Global_active_power','Global_reactive_power','Voltage','Global_intensity',
                    'Sub_metering_1','Sub_metering_2','Sub_metering_3']
    for c in numeric_cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors='coerce')
    return df

def add_datetime_and_weekday(df):
    '''Cria coluna datetime combinando Date + Time, e coluna Weekday.'''
    df = df.copy()
    df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%d/%m/%Y %H:%M:%S', errors='coerce')
    df['Date_dt'] = pd.to_datetime(df['Date'], format='%d/%m/%Y', errors='coerce')
    df['Weekday'] = df['Date_dt'].dt.day_name(locale='en_US')
    df['Year'] = df['Date_dt'].dt.year
    df['Month'] = df['Date_dt'].dt.month
    df['Day'] = df['Date_dt'].dt.day
    return df

def plot_simple_line(x, y, title, xlabel, ylabel):
    plt.figure()
    plt.plot(x, y)
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.show()

def rmse(y_true, y_pred):
    return np.sqrt(mean_squared_error(y_true, y_pred))
```

### Instru√ß√µes para Execu√ß√£o Individual

**Para cada exerc√≠cio, copie e cole o c√≥digo correspondente no Google Colab:**

1. **Execute primeiro** o bloco de prepara√ß√£o
2. **Execute as fun√ß√µes auxiliares**
3. **Execute cada exerc√≠cio individualmente** (Q1, Q2, Q3, etc.)
4. **Para Orange Data Mining** (Q36-Q40), use a interface visual conforme instru√ß√µes

### Dicas para Google Colab
- Use `plt.show()` para exibir gr√°ficos
- Para datasets grandes, considere usar `df.head()` para preview
- Se houver erro de mem√≥ria, use amostragem: `df.sample(n=10000)`
- Para salvar resultados: `plt.savefig('grafico.png')`

## üìà An√°lises Realizadas

### Parte 1 - Exerc√≠cios Iniciais (Power Dataset) - 20 quest√µes

#### **Q1 - Carregamento e Exibi√ß√£o**
```python
power = parse_power_dataset(POWER_PATH)
print("Q1) Primeiras 10 linhas:\n", power.head(10), "\n")
```
- **Fun√ß√£o**: `parse_power_dataset()` carrega o dataset com separador ';' e valores '?' como NaN
- **Sa√≠da**: Exibe as 10 primeiras linhas do dataset
- **Google Colab**: Copie e cole este bloco para executar

#### **Q2 - Explica√ß√£o Conceitual**
- **Conte√∫do**: Explica√ß√£o da diferen√ßa entre Global_active_power e Global_reactive_power
- **Resposta**: Global_active_power = energia √∫til consumida; Global_reactive_power = energia reativa (n√£o √∫til)

#### **Q3 - Valores Ausentes**
```python
missing_counts = power.isna().sum()
print("Q3) Total de linhas:", len(power))
print("Valores ausentes por coluna:\n", missing_counts, "\n")
```
- **Fun√ß√£o**: Conta valores ausentes por coluna usando `.isna().sum()`
- **Sa√≠da**: Total de linhas e contagem de NaN por coluna

#### **Q4 - Convers√£o Datetime**
```python
power = add_datetime_and_weekday(power)
print("Q4) Colunas Date_dt e Weekday criadas. Preview:\n", power[['Date','Date_dt','Weekday']].head(), "\n")
```
- **Fun√ß√£o**: `add_datetime_and_weekday()` combina Date+Time e cria colunas Year, Month, Day, Weekday
- **Sa√≠da**: Preview das novas colunas temporais

#### **Q5 - M√©dia Di√°ria 2007**
```python
p2007 = power[power['Year'] == 2007].dropna(subset=['Global_active_power', 'Date_dt'])
daily_mean_2007 = p2007.groupby('Date_dt')['Global_active_power'].mean().rename('DailyMeanGAP')
print("Q5) M√©dia di√°ria 2007 ‚Äì resumo:\n", daily_mean_2007.describe(), "\n")
```
- **Fun√ß√£o**: Filtra dados de 2007 e calcula m√©dia di√°ria de Global_active_power
- **Sa√≠da**: Estat√≠sticas descritivas das m√©dias di√°rias

#### **Q6 - Gr√°fico de Um Dia**
```python
one_day = p2007.dropna(subset=['Datetime']).set_index('Datetime').between_time('00:00','23:59')
if not one_day.empty:
    date_example = one_day.index.date[0]
    day_slice = one_day[one_day.index.date == date_example]['Global_active_power']
    plot_simple_line(day_slice.index, day_slice.values,
                     f"Q6) Global_active_power ao longo do dia - {date_example}",
                     "Hora", "kW")
```
- **Fun√ß√£o**: Seleciona um dia completo e plota varia√ß√£o hor√°ria
- **Sa√≠da**: Gr√°fico de linha mostrando consumo ao longo de 24h

#### **Q7 - Histograma Voltage**
```python
plt.figure()
power['Voltage'].dropna().hist(bins=50)
plt.title("Q7) Distribui√ß√£o de Voltage")
plt.xlabel("Voltage (V)")
plt.ylabel("Frequ√™ncia")
plt.show()
```
- **Fun√ß√£o**: Cria histograma da distribui√ß√£o de tens√£o
- **Sa√≠da**: Gr√°fico de barras com 50 bins

#### **Q8 - Consumo Mensal**
```python
monthly_mean = power.dropna(subset=['Global_active_power']).groupby(['Year','Month'])['Global_active_power'].mean()
print("Q8) Primeiros meses e estat√≠sticas:\n", monthly_mean.head(), "\n", monthly_mean.describe(), "\n")
```
- **Fun√ß√£o**: Agrupa por ano/m√™s e calcula m√©dia de Global_active_power
- **Sa√≠da**: S√©rie temporal com m√©dias mensais

#### **Q9 - Dia de Maior Consumo**
```python
daily_mean_all = power.dropna(subset=['Global_active_power','Date_dt']).groupby('Date_dt')['Global_active_power'].mean()
max_day = daily_mean_all.idxmax()
max_value = daily_mean_all.max()
print("Q9) Dia com maior consumo m√©dio:", max_day, "Valor (kW):", max_value, "\n")
```
- **Fun√ß√£o**: Calcula m√©dias di√°rias e identifica o dia com maior valor
- **Sa√≠da**: Data e valor do maior consumo di√°rio

#### **Q10 - Compara√ß√£o Fim de Semana**
```python
power['IsWeekend'] = power['Date_dt'].dt.weekday >= 5
weekday_mean = power.loc[power['IsWeekend'] == False].groupby('Date_dt')['Global_active_power'].mean().mean()
weekend_mean = power.loc[power['IsWeekend'] == True].groupby('Date_dt')['Global_active_power'].mean().mean()
print("Q10) M√©dia di√°ria semana (kW):", weekday_mean, " | fim de semana (kW):", weekend_mean, "\n")
```
- **Fun√ß√£o**: Cria flag de fim de semana e compara m√©dias
- **Sa√≠da**: Duas m√©dias comparativas

#### **Q11 - Matriz de Correla√ß√£o**
```python
corr_vars = ['Global_active_power','Global_reactive_power','Voltage','Global_intensity']
corr_df = power[corr_vars].dropna().corr()
print("Q11) Correla√ß√£o entre vari√°veis:\n", corr_df, "\n")
```
- **Fun√ß√£o**: Calcula correla√ß√£o entre 4 vari√°veis principais
- **Sa√≠da**: Matriz de correla√ß√£o 4x4

#### **Q12 - Total Submedi√ß√µes**
```python
for c in ['Sub_metering_1','Sub_metering_2','Sub_metering_3']:
    if c not in power.columns:
        power[c] = np.nan
power['Total_Sub_metering'] = power[['Sub_metering_1','Sub_metering_2','Sub_metering_3']].sum(axis=1, min_count=1)
print("Q12) Total_Sub_metering criada. Preview:\n", power[['Sub_metering_1','Sub_metering_2','Sub_metering_3','Total_Sub_metering']].head(), "\n")
```
- **Fun√ß√£o**: Soma as 3 submedi√ß√µes criando nova vari√°vel
- **Sa√≠da**: Preview da nova coluna calculada

#### **Q13 - Compara√ß√£o Mensal**
```python
monthly_tot_sub = power.groupby(['Year','Month'])['Total_Sub_metering'].mean()
monthly_gap = power.groupby(['Year','Month'])['Global_active_power'].mean()
compare = pd.DataFrame({
    'Monthly_Total_Sub_metering': monthly_tot_sub,
    'Monthly_Global_active_power': monthly_gap
}).dropna()
compare['Exceeds'] = compare['Monthly_Total_Sub_metering'] > compare['Monthly_Global_active_power']
print("Q13) Meses em que Total_Sub_metering > Global_active_power (m√©dias mensais):\n", compare[compare['Exceeds']==True].head(), "\n")
```
- **Fun√ß√£o**: Compara m√©dias mensais de submedi√ß√µes vs consumo global
- **Sa√≠da**: Meses onde submedi√ß√µes excedem consumo global

#### **Q14 - S√©rie Temporal Voltage 2008**
```python
p2008 = power[power['Year'] == 2008].dropna(subset=['Datetime','Voltage'])
if not p2008.empty:
    ts2008 = p2008.set_index('Datetime')['Voltage'].resample('1D').mean()
    plot_simple_line(ts2008.index, ts2008.values, "Q14) Voltage - M√©dia di√°ria (2008)", "Data", "Voltage (V)")
```
- **Fun√ß√£o**: Filtra 2008 e cria s√©rie temporal di√°ria de tens√£o
- **Sa√≠da**: Gr√°fico de linha com evolu√ß√£o di√°ria

#### **Q15 - Compara√ß√£o Sazonal**
```python
gap = power.dropna(subset=['Global_active_power'])
summer = gap[gap['Month'].isin([6,7,8])]['Global_active_power'].mean()
winter = gap[gap['Month'].isin([12,1,2])]['Global_active_power'].mean()
print("Q15) M√©dia GAP - Ver√£o (JJA):", summer, " | Inverno (DJF):", winter, "\n")
```
- **Fun√ß√£o**: Compara m√©dias de ver√£o (JJA) vs inverno (DJF)
- **Sa√≠da**: Duas m√©dias sazonais

#### **Q16 - Amostragem 1%**
```python
sample = power.sample(frac=0.01, random_state=RANDOM_STATE)
plt.figure()
power['Global_active_power'].dropna().plot(kind='kde')
sample['Global_active_power'].dropna().plot(kind='kde')
plt.title("Q16) Distribui√ß√£o KDE - Completa vs Amostra 1%")
plt.xlabel("Global_active_power (kW)")
plt.legend(["Completa","Amostra 1%"])
plt.show()
```
- **Fun√ß√£o**: Amostra 1% e compara distribui√ß√µes com KDE
- **Sa√≠da**: Gr√°fico sobreposto das duas distribui√ß√µes

#### **Q17 - Normaliza√ß√£o Min-Max**
```python
num_vars = ['Global_active_power','Global_reactive_power','Voltage','Global_intensity','Total_Sub_metering']
scaled_df = power[num_vars].copy()
scaler = MinMaxScaler()
scaled_vals = scaler.fit_transform(scaled_df.values)
scaled_df = pd.DataFrame(scaled_vals, columns=num_vars, index=power.index)
print("Q17) Exemplo de dados escalados (Min-Max):\n", scaled_df.head(), "\n")
```
- **Fun√ß√£o**: Aplica MinMaxScaler nas 5 vari√°veis num√©ricas
- **Sa√≠da**: DataFrame com valores entre 0 e 1

#### **Q18 - K-Means Clustering**
```python
daily = power.dropna(subset=['Date_dt']).groupby('Date_dt')[['Global_active_power','Global_reactive_power','Voltage','Global_intensity','Total_Sub_metering']].mean().dropna()
km = KMeans(n_clusters=3, random_state=RANDOM_STATE, n_init=10)
daily['cluster'] = km.fit_predict(StandardScaler().fit_transform(daily[['Global_active_power','Global_reactive_power','Voltage','Global_intensity','Total_Sub_metering']]))
print("Q18) Tamanho dos clusters (dias):\n", daily['cluster'].value_counts(), "\n")
print("Q18) Perfil m√©dio por cluster:\n", daily.groupby('cluster').mean(), "\n")
```
- **Fun√ß√£o**: Agrupa por dia, aplica StandardScaler e K-Means com 3 clusters
- **Sa√≠da**: Tamanho dos clusters e perfis m√©dios

#### **Q19 - Decomposi√ß√£o S√©rie Temporal**
```python
if HAS_STATSmodels:
    gp = power.dropna(subset=['Datetime','Global_active_power']).set_index('Datetime')['Global_active_power'].resample('1H').mean().dropna()
    if len(gp) > 0:
        start = gp.index.min()
        end = start + pd.DateOffset(months=6)
        gp_6m = gp.loc[(gp.index >= start) & (gp.index < end)]
        if len(gp_6m) > 24*30:
            result = seasonal_decompose(gp_6m, model='additive', period=24)
            result.plot()
            plt.suptitle("Q19) Decomposi√ß√£o de S√©rie (6 meses) - Global_active_power")
            plt.show()
```
- **Fun√ß√£o**: Decomp√µe s√©rie temporal em tend√™ncia, sazonalidade e res√≠duo
- **Sa√≠da**: 4 gr√°ficos (original, tend√™ncia, sazonalidade, res√≠duo)
- **Depend√™ncia**: Requer statsmodels

#### **Q20 - Regress√£o Linear**
```python
df_lr = power[['Global_active_power','Global_intensity']].dropna()
X = df_lr[['Global_intensity']].values
y = df_lr['Global_active_power'].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)
linreg = LinearRegression().fit(X_train, y_train)
pred = linreg.predict(X_test)
print("Q20) RMSE:", rmse(y_test, pred))
print("Coeficiente:", linreg.coef_[0], "Intercepto:", linreg.intercept_, "\n")
```
- **Fun√ß√£o**: Treina regress√£o linear Global_active_power ~ Global_intensity
- **Sa√≠da**: RMSE, coeficiente e intercepto

### Parte 2 - Exerc√≠cios Adicionais (Power Dataset) - 5 quest√µes

#### **Q21 - Padr√£o Hor√°rio**
```python
s_hourly = power.dropna(subset=['Datetime']).set_index('Datetime')['Global_active_power'].resample('1H').mean().dropna()
hourly_pattern = s_hourly.groupby(s_hourly.index.hour).mean()
print("Q21) Top 5 hor√°rios de maior consumo m√©dio:\n", hourly_pattern.sort_values(ascending=False).head(5), "\n")
plt.figure()
plt.plot(hourly_pattern.index, hourly_pattern.values)
plt.title("Q21) Padr√£o m√©dio por hora do dia - Global_active_power")
plt.xlabel("Hora do dia")
plt.ylabel("kW (m√©dia)")
plt.show()
```
- **Fun√ß√£o**: Reamostra para hora e calcula padr√£o m√©dio por hora
- **Sa√≠da**: Top 5 hor√°rios + gr√°fico de linha

#### **Q22 - Autocorrela√ß√£o**
```python
def autocorr_at_lag(series, lag):
    return series.autocorr(lag=lag)
for lag in [1, 24, 48]:
    print(f"Q22) Autocorrela√ß√£o (lag={lag}h):", autocorr_at_lag(s_hourly, lag))
```
- **Fun√ß√£o**: Calcula autocorrela√ß√£o em lags de 1h, 24h e 48h
- **Sa√≠da**: 3 valores de autocorrela√ß√£o

#### **Q23 - PCA**
```python
sel = power[['Global_active_power','Global_reactive_power','Voltage','Global_intensity']].dropna()
X_std = StandardScaler().fit_transform(sel.values)
pca = PCA(n_components=2, random_state=RANDOM_STATE)
X_pca = pca.fit_transform(X_std)
print("Q23) Vari√¢ncia explicada:", pca.explained_variance_ratio_, "\n")
```
- **Fun√ß√£o**: Aplica PCA reduzindo 4 vari√°veis para 2 componentes
- **Sa√≠da**: Propor√ß√£o de vari√¢ncia explicada por cada componente

#### **Q24 - Clustering PCA**
```python
km_pca = KMeans(n_clusters=3, random_state=RANDOM_STATE, n_init=10).fit(X_pca)
labels = km_pca.labels_
plt.figure()
plt.scatter(X_pca[:,0], X_pca[:,1], c=labels)
plt.title("Q24) PCA (2D) + KMeans (3 clusters)")
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.show()
```
- **Fun√ß√£o**: Aplica K-Means no espa√ßo PCA 2D
- **Sa√≠da**: Scatter plot colorido por cluster

#### **Q25 - Regress√£o Polinomial**
```python
df_reg = power[['Global_active_power','Voltage']].dropna()
Xv = df_reg[['Voltage']].values
yv = df_reg['Global_active_power'].values
X_train, X_test, y_train, y_test = train_test_split(Xv, yv, test_size=0.2, random_state=RANDOM_STATE)
lin = LinearRegression().fit(X_train, y_train)
pred_lin = lin.predict(X_test)
rmse_lin = rmse(y_test, pred_lin)
poly = PolynomialFeatures(degree=2, include_bias=False)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)
lin_poly = LinearRegression().fit(X_train_poly, y_train)
pred_poly = lin_poly.predict(X_test_poly)
rmse_poly = rmse(y_test, pred_poly)
print("Q25) RMSE Linear:", rmse_lin, " | RMSE Polinomial (g2):", rmse_poly, "\n")
```
- **Fun√ß√£o**: Compara regress√£o linear vs polinomial (grau 2)
- **Sa√≠da**: RMSE de ambos os modelos + gr√°fico comparativo

### Parte 3 - Appliances Energy Prediction - 10 quest√µes

#### **Q26 - Inspe√ß√£o Inicial**
```python
appl = pd.read_csv(APPLIANCES_PATH)
print("Q26) .info():")
print(appl.info())
print("Q26) .describe():\n", appl.describe(include='all'), "\n")
```
- **Fun√ß√£o**: Carrega dataset e exibe informa√ß√µes b√°sicas
- **Sa√≠da**: Info do DataFrame + estat√≠sticas descritivas

#### **Q27 - Distribui√ß√£o Appliances**
```python
plt.figure()
appl['Appliances'].dropna().hist(bins=50)
plt.title("Q27) Histograma - Appliances")
plt.xlabel("Wh")
plt.ylabel("Frequ√™ncia")
plt.show()
if 'date' in appl.columns:
    appl['date'] = pd.to_datetime(appl['date'], errors='coerce')
    s_app = appl.dropna(subset=['date']).set_index('date')['Appliances'].resample('1H').mean()
    plot_simple_line(s_app.index, s_app.values, "Q27) Appliances (m√©dia por hora)", "Data/Hora", "Wh")
```
- **Fun√ß√£o**: Cria histograma e s√©rie temporal do consumo
- **Sa√≠da**: Histograma + gr√°fico de linha temporal

#### **Q28 - Correla√ß√µes Ambientais**
```python
cand_cols = [c for c in appl.columns if c.lower().startswith(('t','rh'))]
corr_cols = ['Appliances'] + cand_cols
corr_appl = appl[corr_cols].corr()['Appliances'].sort_values(ascending=False)
print("Q28) Correla√ß√µes (Appliances vs vari√°veis ambientais):\n", corr_appl, "\n")
```
- **Fun√ß√£o**: Calcula correla√ß√µes com vari√°veis de temperatura e umidade
- **Sa√≠da**: S√©rie ordenada de correla√ß√µes

#### **Q29 - Normaliza√ß√£o**
```python
num_cols_appl = appl.select_dtypes(include=[np.number]).columns.tolist()
scaler_app = MinMaxScaler()
appl_scaled = appl.copy()
appl_scaled[num_cols_appl] = scaler_app.fit_transform(appl[num_cols_appl])
print("Q29) Normaliza√ß√£o conclu√≠da. Preview:\n", appl_scaled.head(), "\n")
```
- **Fun√ß√£o**: Aplica MinMaxScaler em todas as colunas num√©ricas
- **Sa√≠da**: Preview dos dados normalizados

#### **Q30 - PCA Appliances**
```python
X_app = appl_scaled[num_cols_appl].dropna().values
pca_app = PCA(n_components=2, random_state=RANDOM_STATE)
X_app_pca = pca_app.fit_transform(X_app)
print("Q30) Vari√¢ncia explicada:", pca_app.explained_variance_ratio_, "\n")
plt.figure()
plt.scatter(X_app_pca[:,0], X_app_pca[:,1])
plt.title("Q30) PCA (2D) - Appliances dataset")
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.show()
```
- **Fun√ß√£o**: Aplica PCA nos dados normalizados
- **Sa√≠da**: Vari√¢ncia explicada + scatter plot 2D

#### **Q31 - Regress√£o Linear M√∫ltipla**
```python
features = [c for c in appl.columns if c.lower().startswith(('t','rh'))]
X = appl[features].fillna(method='ffill').fillna(method='bfill').values
y = appl['Appliances'].values
X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)
lr = LinearRegression().fit(X_tr, y_tr)
pred_lr = lr.predict(X_te)
print("Q31) R¬≤ (teste):", lr.score(X_te, y_te), " | RMSE:", rmse(y_te, pred_lr), "\n")
```
- **Fun√ß√£o**: Treina regress√£o linear m√∫ltipla com vari√°veis ambientais
- **Sa√≠da**: R¬≤ e RMSE do modelo

#### **Q32 - Random Forest Regressor**
```python
rf = RandomForestRegressor(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1)
rf.fit(X_tr, y_tr)
pred_rf = rf.predict(X_te)
print("Q32) RMSE RF:", rmse(y_te, pred_rf), " | (Compara√ß√£o com Linear:", rmse(y_te, pred_lr), ")\n")
```
- **Fun√ß√£o**: Treina Random Forest com 200 √°rvores
- **Sa√≠da**: RMSE comparativo com regress√£o linear

#### **Q33 - K-Means M√∫ltiplos**
```python
Xk = appl_scaled[features].dropna().values
for k in [3,4,5]:
    kmx = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10).fit(Xk)
    print(f"Q33) k={k}: tamanhos dos clusters =", np.bincount(kmx.labels_))
```
- **Fun√ß√£o**: Testa K-Means com k=3,4,5
- **Sa√≠da**: Tamanho dos clusters para cada k

#### **Q34 - Classifica√ß√£o Bin√°ria**
```python
median_app = np.median(appl['Appliances'].values)
appl_cls = appl_scaled.copy()
appl_cls['HighUsage'] = (appl['Appliances'] > median_app).astype(int)
Xc = appl_cls[features].values
yc = appl_cls['HighUsage'].values
Xc_tr, Xc_te, yc_tr, yc_te = train_test_split(Xc, yc, test_size=0.2, random_state=RANDOM_STATE, stratify=yc)

logit = LogisticRegression(max_iter=1000).fit(Xc_tr, yc_tr)
pred_logit = logit.predict(Xc_te)

rfc = RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE, n_jobs=-1).fit(Xc_tr, yc_tr)
pred_rfc = rfc.predict(Xc_te)

print("Q34) LogReg - Acc/Prec/Rec/F1:",
      accuracy_score(yc_te, pred_logit),
      precision_score(yc_te, pred_logit),
      recall_score(yc_te, pred_logit),
      f1_score(yc_te, pred_logit))
print("Q34) RFClf  - Acc/Prec/Rec/F1:",
      accuracy_score(yc_te, pred_rfc),
      precision_score(yc_te, pred_rfc),
      recall_score(yc_te, pred_rfc),
      f1_score(yc_te, pred_rfc), "\n")
```
- **Fun√ß√£o**: Cria vari√°vel bin√°ria (alto/baixo consumo) e treina 2 classificadores
- **Sa√≠da**: M√©tricas de ambos os modelos

#### **Q35 - Avalia√ß√£o Detalhada**
```python
print("Q35) == Logistic Regression ==")
print(confusion_matrix(yc_te, pred_logit))
print(classification_report(yc_te, pred_logit))
print("Q35) == Random Forest Classifier ==")
print(confusion_matrix(yc_te, pred_rfc))
print(classification_report(yc_te, pred_rfc))
print("Q35) Observe em qual classe ocorrem mais erros (alto vs baixo consumo).")
```
- **Fun√ß√£o**: Gera matriz de confus√£o e relat√≥rio detalhado
- **Sa√≠da**: Matrizes de confus√£o e relat√≥rios de classifica√ß√£o

### Parte 4 - Orange Data Mining - 5 quest√µes

#### **Q36 - Importa√ß√£o e Visualiza√ß√£o**
- **Widget**: CSV File Import ‚Üí Data Table
- **Configura√ß√£o**: Separador ';', Missing '?', Header Sim
- **Objetivo**: Verificar n√∫mero de inst√¢ncias e vari√°veis

#### **Q37 - Amostragem 1%**
- **Widget**: CSV ‚Üí Sample Data (Proportion = 0.01) ‚Üí Distribution
- **Objetivo**: Comparar distribui√ß√£o da amostra vs base completa

#### **Q38 - Distribui√ß√£o do Consumo**
- **Widget**: Distribution (Global_active_power)
- **Objetivo**: Analisar concentra√ß√£o em valores baixos/altos

#### **Q39 - Scatter Plot**
- **Widget**: Scatter Plot (X=Voltage, Y=Global_intensity)
- **Objetivo**: Verificar correla√ß√£o visual entre vari√°veis

#### **Q40 - K-Means Visual**
- **Widget**: k-Means (k=3) ‚Üí Scatter Plot (Color=Cluster)
- **Features**: Sub_metering_1, Sub_metering_2, Sub_metering_3
- **Objetivo**: Interpretar padr√µes distintos de consumo por cluster

## üìä Principais Resultados

### Insights de Consumo Energ√©tico
- **Padr√£o sazonal**: Maior consumo no ver√£o vs inverno
- **Padr√£o di√°rio**: Picos de consumo em hor√°rios espec√≠ficos
- **Diferen√ßa semanal**: Consumo maior em dias √∫teis vs fins de semana
- **Correla√ß√µes**: Rela√ß√£o entre tens√£o, intensidade e consumo ativo

### Performance dos Modelos
- **Regress√£o Linear**: Baseline para predi√ß√£o de consumo
- **Random Forest**: Melhor performance em tarefas de regress√£o
- **Classifica√ß√£o**: Diferencia√ß√£o entre alto e baixo consumo
- **Clustering**: Identifica√ß√£o de padr√µes distintos de uso

## üîß Funcionalidades Implementadas

### Fun√ß√µes Auxiliares
- `parse_power_dataset()` - Carregamento e limpeza de dados
- `add_datetime_and_weekday()` - Cria√ß√£o de vari√°veis temporais
- `hourly_series()` - Agrega√ß√£o por hora
- `plot_simple_line()` - Visualiza√ß√£o simplificada
- `rmse()` - C√°lculo de erro quadr√°tico m√©dio

### An√°lises Automatizadas
- Tratamento de valores ausentes
- Normaliza√ß√£o e padroniza√ß√£o
- An√°lise de correla√ß√µes
- Decomposi√ß√£o de s√©ries temporais
- Valida√ß√£o cruzada de modelos

## üìù Observa√ß√µes T√©cnicas

- **Random State**: Fixado em 42 para reprodutibilidade
- **Tratamento de Missing**: Valores '?' convertidos para NaN
- **Escalamento**: MinMaxScaler e StandardScaler aplicados conforme necess√°rio
- **Valida√ß√£o**: Split 80/20 para treino/teste
- **M√©tricas**: RMSE para regress√£o, acur√°cia/precis√£o/recall/F1 para classifica√ß√£o

## üéØ Objetivos de Aprendizado

Este projeto demonstra:
- **An√°lise explorat√≥ria** de dados temporais
- **Visualiza√ß√£o** de padr√µes e tend√™ncias
- **Pr√©-processamento** e limpeza de dados
- **Modelagem preditiva** com diferentes algoritmos
- **Avalia√ß√£o** de performance de modelos
- **Clustering** e redu√ß√£o de dimensionalidade
- **Integra√ß√£o** entre Python e Orange Data Mining

## üìö Refer√™ncias

### Datasets
- [Individual Household Electric Power Consumption](https://archive.ics.uci.edu/dataset/235/individual+household+electric+power+consumption)
- [Appliances Energy Prediction](https://archive.ics.uci.edu/dataset/374/appliances+energy+prediction)

### Documenta√ß√£o T√©cnica
- [Scikit-learn Documentation](https://scikit-learn.org/stable/)
- [Orange Data Mining Platform](https://orangedatamining.com/)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Matplotlib Gallery](https://matplotlib.org/stable/gallery/)

### Widgets Orange Data Mining
- [Orange Widget Catalog](https://orangedatamining.com/widget-catalog/)
- [CSV File Import](https://orangedatamining.com/widget-catalog/data/csvfile/)
- [Data Table](https://orangedatamining.com/widget-catalog/data/datatable/)
- [Sample Data](https://orangedatamining.com/widget-catalog/data/sampledata/)
- [Distribution](https://orangedatamining.com/widget-catalog/visualize/distribution/)
- [Scatter Plot](https://orangedatamining.com/widget-catalog/visualize/scatterplot/)
- [k-Means](https://orangedatamining.com/widget-catalog/unsupervised/kmeans/)

## üìã Instru√ß√µes de Entrega

- ‚úÖ **Desenvolvimento em grupo** permitido
- ‚úÖ **Apenas um integrante** submete a atividade
- ‚úÖ **Enviar apenas o link** do reposit√≥rio GitHub
- ‚úÖ **Total de exerc√≠cios**: 40 (20 em 20/08 + 20 em 27/08)
- ‚úÖ **Reposit√≥rio GitHub** com README.md detalhado
- ‚úÖ **Notebook Python** com resolu√ß√µes das tarefas

---
